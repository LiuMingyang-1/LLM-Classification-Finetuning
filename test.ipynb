{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install torch transformers peft datasets pandas accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d23c7dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/llm-classification-finetuning/.venv/lib/python3.10/site-packages/pandas/__init__.py:26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/Documents/code/llm-classification-finetuning/.venv/lib/python3.10/site-packages/pandas/compat/__init__.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     HAS_PYARROW,\n\u001b[1;32m     31\u001b[0m     pa_version_under10p1,\n\u001b[1;32m     32\u001b[0m     pa_version_under11p0,\n\u001b[1;32m     33\u001b[0m     pa_version_under13p0,\n\u001b[1;32m     34\u001b[0m     pa_version_under14p0,\n\u001b[1;32m     35\u001b[0m     pa_version_under14p1,\n\u001b[1;32m     36\u001b[0m     pa_version_under16p0,\n\u001b[1;32m     37\u001b[0m     pa_version_under17p0,\n\u001b[1;32m     38\u001b[0m     pa_version_under18p0,\n\u001b[1;32m     39\u001b[0m     pa_version_under19p0,\n\u001b[1;32m     40\u001b[0m     pa_version_under20p0,\n\u001b[1;32m     41\u001b[0m     pa_version_under21p0,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m F\n",
      "File \u001b[0;32m~/Documents/code/llm-classification-finetuning/.venv/lib/python3.10/site-packages/pandas/compat/pyarrow.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     _palv \u001b[38;5;241m=\u001b[39m Version(Version(pa\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version)\n\u001b[1;32m     11\u001b[0m     pa_version_under10p1 \u001b[38;5;241m=\u001b[39m _palv \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/llm-classification-finetuning/.venv/lib/python3.10/site-packages/pyarrow/__init__.py:61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (BuildInfo, CppBuildInfo, RuntimeInfo, set_timezone_db_path,\n\u001b[1;32m     63\u001b[0m                          MonthDayNano, VersionInfo, build_info, cpp_build_info,\n\u001b[1;32m     64\u001b[0m                          cpp_version, cpp_version_info, runtime_info,\n\u001b[1;32m     65\u001b[0m                          cpu_count, set_cpu_count, enable_signal_handlers,\n\u001b[1;32m     66\u001b[0m                          io_thread_count, set_io_thread_count)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow_versions\u001b[39m():\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# --- 配置 ---\n",
    "MODEL_NAME = \"zai-org/chatglm3-6b\"  # 替换为你本地的模型路径\n",
    "MAX_LENGTH = 2048 # 显存够的话可以开到 2048\n",
    "OUTPUT_DIR = \"./chatglm3_kaggle_output\"\n",
    "\n",
    "# --- 1. 数据处理 ---\n",
    "def prepare_dataset(csv_path, tokenizer):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.fillna(\"\", inplace=True)\n",
    "\n",
    "    # 转换标签\n",
    "    def get_label(row):\n",
    "        if row['winner_model_a'] == 1: return 0\n",
    "        if row['winner_model_b'] == 1: return 1\n",
    "        return 2 # Tie\n",
    "    \n",
    "    df['label'] = df.apply(get_label, axis=1)\n",
    "    \n",
    "    # 构建输入文本\n",
    "    # 我们可以稍微精简一下 Prompt，让模型聚焦于比较\n",
    "    def construct_prompt(row):\n",
    "        return (\n",
    "            f\"<|user|>\\nPlease evaluate these two responses:\\n\\n\"\n",
    "            f\"[Prompt]: {row['prompt']}\\n\\n\"\n",
    "            f\"[Response A]: {row['response_a']}\\n\\n\"\n",
    "            f\"[Response B]: {row['response_b']}\\n\\n\"\n",
    "            f\"Which is better?\\n<|assistant|>\"\n",
    "        )\n",
    "    \n",
    "    df['text'] = df.apply(construct_prompt, axis=1)\n",
    "    \n",
    "    # 转换为 Hugging Face Dataset 格式\n",
    "    raw_dataset = Dataset.from_pandas(df[['text', 'label']])\n",
    "    \n",
    "    # Tokenize 函数\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(\n",
    "            examples['text'], \n",
    "            truncation=True, \n",
    "            max_length=MAX_LENGTH,\n",
    "            padding=False # Padding 交给 DataCollator 动态处理，节省显存\n",
    "        )\n",
    "    \n",
    "    tokenized_dataset = raw_dataset.map(preprocess_function, batched=True)\n",
    "    \n",
    "    # 划分训练集和验证集\n",
    "    return tokenized_dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# --- 2. 评估指标 ---\n",
    "# Trainer 会自动调用这个函数来计算准确率\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "def main():\n",
    "    # --- 加载 Tokenizer ---\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "    \n",
    "    # ChatGLM3 的小坑：它默认没有 pad_token，训练时必须指定\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # --- 准备数据 ---\n",
    "    dataset = prepare_dataset(\"train.csv\", tokenizer)\n",
    "    \n",
    "    # --- 加载模型 ---\n",
    "    # num_labels=3 对应 A胜, B胜, 平局\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=3, \n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\" # 自动分配显存\n",
    "    )\n",
    "    \n",
    "    # 修复 ChatGLM 分类头的问题\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    # --- 配置 LoRA (PEFT) ---\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS, # 任务类型：序列分类\n",
    "        inference_mode=False,\n",
    "        r=8,           # 秩，越大参数越多但可能效果越好，通常 8 或 16\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"query_key_value\"] # ChatGLM 的核心层\n",
    "    )\n",
    "    \n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters() # 打印可训练参数量，确认 LoRA 生效\n",
    "\n",
    "    # --- 3. 配置 Trainer ---\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        learning_rate=2e-4,\n",
    "        per_device_train_batch_size=2, # 如果显存不够，改小这个\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4, # 显存不够时，用这个模拟大 Batch\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"steps\", # 每隔多少步评估一次\n",
    "        eval_steps=100,              # 每 100 步评估\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        logging_steps=10,\n",
    "        fp16=True,                   # 开启混合精度\n",
    "        report_to=\"none\",            # 不想用 wandb 就填 none\n",
    "        remove_unused_columns=False, # 防止 Dataset 里的列被错误删除\n",
    "        label_names=[\"labels\"]       # 明确告诉 Trainer 哪一列是标签\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # --- 开始训练 ---\n",
    "    trainer.train()\n",
    "    \n",
    "    # --- 保存模型 ---\n",
    "    trainer.save_model(OUTPUT_DIR)\n",
    "    print(\"Training finished and model saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
